{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch import distributions\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2 # Reload all modueles every time before executing the Python code typed.\n",
    "\n",
    "import project\n",
    "import project.networks.net as net\n",
    "from project.models.triple_well   import TripleWell\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cbook as cbook\n",
    "from matplotlib import cm\n",
    "import scipy.ndimage\n",
    "nbins=100\n",
    "from scipy.stats import kde\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize triple well potential\n",
    "The energy landscape for the double well model system is given by eq. 18 of Noe et al.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(x, y): # default parameter values given in pg. 4 of the SI \n",
    "    return 3 * (3 * np.exp( -x**2 - (y - (1/3))**2) - \\\n",
    "                3 * np.exp( -x**2 - (y - (5/3))**2) - \\\n",
    "                    5 * np.exp( - (x - 1)**2 - y**2) - \\\n",
    "                        5 * np.exp( - (x + 1)**2 - y**2) + \\\n",
    "                            0.2*x + 0.2*(y - (1/3)**4)) + 5 + 0.1 * (x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2(x, y): # default parameter values given in pg. 4 of the SI \n",
    "    return 3 * np.exp( - x**2 - (y - (1/3))**2) - \\\n",
    "                3 * np.exp( - x**2 - (y - (5/3))**2) - \\\n",
    "                    5 * np.exp( - (x - 1)**2 - y**2) - \\\n",
    "                        5 * np.exp( - (x + 1)**2 - y**2) + \\\n",
    "                            0.2*(x**4) + 0.2*(y - (1/3))**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_illustrate = np.linspace(-2.5,2.5,100)\n",
    "y_illustrate = np.linspace(-2,3,100)\n",
    "xx, yy = np.meshgrid(x_illustrate, y_illustrate, sparse=True)\n",
    "E_illustrate = E2(xx,yy)\n",
    "\n",
    "fig = go.Figure(data =\n",
    "    go.Contour(\n",
    "        z=E_illustrate,\n",
    "        x=x_illustrate, \n",
    "        y=y_illustrate,\n",
    "        reversescale = True,\n",
    "        colorscale = \"viridis\",\n",
    "        contours=dict(\n",
    "            start=-10,\n",
    "            end=5,\n",
    "            size=1,\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title=\"Plot Title\",\n",
    "    width=600,\n",
    "    height=500,\n",
    "    font=dict(\n",
    "        family=\"Lato\",\n",
    "        size=30,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    "    xaxis_title=\"x1\",\n",
    "    yaxis_title=\"x2\",\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = -3,\n",
    "        dtick = 1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_image(\"images/double_well.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this energy landscape as is done in Fig. 2 of Noe et al: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_illustrate = np.linspace(-2.5,2.5,100)\n",
    "y_illustrate = np.linspace(-2,3,100)\n",
    "xx, yy = np.meshgrid(x_illustrate, y_illustrate, sparse=True)\n",
    "E_illustrate = E(xx,yy)\n",
    "\n",
    "fig = go.Figure(data =\n",
    "    go.Contour(\n",
    "        z=E_illustrate,\n",
    "        x=x_illustrate, \n",
    "        y=y_illustrate,\n",
    "        reversescale = True,\n",
    "        colorscale = \"viridis\",\n",
    "        contours=dict(\n",
    "            start=-10,\n",
    "            end=5,\n",
    "            size=1,\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title=\"Plot Title\",\n",
    "    width=600,\n",
    "    height=500,\n",
    "    font=dict(\n",
    "        family=\"Lato\",\n",
    "        size=30,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    "    xaxis_title=\"x1\",\n",
    "    yaxis_title=\"x2\",\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = -3,\n",
    "        dtick = 1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_image(\"images/double_well.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the report, matplotlib works better for visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (6,4))\n",
    "\n",
    "plt.contour(x_illustrate, y_illustrate, E_illustrate,np.arange(-10, 5, 1),extend='both',colors='k');\n",
    "plt.contourf(x_illustrate, y_illustrate, E_illustrate,np.arange(-10, 5, 1),extend='both',cmap='viridis_r');\n",
    "clb = plt.colorbar()\n",
    "clb.ax.set_title(r'$H(\\mathbf{x})$')\n",
    "\n",
    "my_font_size = 16 \n",
    "plt.xlabel(r\"$x_1$\", fontsize = my_font_size)\n",
    "plt.ylabel(r\"$x_2$\", fontsize = my_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/double_well_potential.png\", dpi=600, transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks slightly different, specifically the minimum seem to be located at different positions from that in the paper. Let's plot $E=f(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(x=x_illustrate, y=E(x_illustrate,0)))\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"E\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(x=y_illustrate, y=E(0,y_illustrate)))\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"E\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample configurations\n",
    "Let's now generate sample configurations we will use as our input data set. These are meant to represent for example the results of molecular dynamics simulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_state_a, y_state_a = np.random.multivariate_normal([-1.15,0], [[0.04, 0],[0,0.05]], 500).T\n",
    "x_state_b, y_state_b = np.random.multivariate_normal([1.15,0], [[0.04, 0],[0,0.05]], 500).T\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Contour(\n",
    "        z=E_illustrate,\n",
    "        x=x_illustrate, \n",
    "        y=y_illustrate,\n",
    "        reversescale = True,\n",
    "        colorscale = \"viridis\",\n",
    "        contours=dict(\n",
    "            start=-10,\n",
    "            end=5,\n",
    "            size=1,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_a,\n",
    "        y=y_state_a,\n",
    "        mode=\"markers\",\n",
    "        name='',\n",
    "        marker_color=\"royalblue\"\n",
    "    ))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_b,\n",
    "        y=y_state_b,\n",
    "        mode=\"markers\",\n",
    "        name='',\n",
    "        marker_color=\"white\"\n",
    "    ))\n",
    "\n",
    "# fig.update_xaxes(range=[-3,3])\n",
    "# fig.update_yaxes(range=[-7,7])\n",
    "\n",
    "fig.update_layout(\n",
    "    #title=\"Plot Title\",\n",
    "    width=600,\n",
    "    height=500,\n",
    "    font=dict(\n",
    "        family=\"Lato\",\n",
    "        size=30,\n",
    "        color=\"#7f7f7f\"\n",
    "    ),\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = -3,\n",
    "        dtick = 1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"double_well_with_points.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is perhaps fine, but really what we should be doining is generating them via Metropolis Monte Carlo as is done in the Noe et al. (2019) paper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis Monte Carlo for training set generation\n",
    "sigma = 0.1\n",
    "training_set_state_a = np.zeros((500,2))\n",
    "training_set_state_a = np.zeros((500,2))\n",
    "\n",
    "for i in range(training_set_state_a.shape[0]):\n",
    "    pass\n",
    "    # create configuration here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_state_a, y_state_a = np.random.multivariate_normal([-1.8,0], [[0.05, 0],[0,1]], 900).T\n",
    "# x_state_b, y_state_b = np.random.multivariate_normal([1.8,0], [[0.05, 0],[0,1]], 100).T\n",
    "\n",
    "x_state_a, y_state_a = np.random.multivariate_normal([-1.15,0], [[0.04, 0],[0,0.05]], 600).T\n",
    "x_state_b, y_state_b = np.random.multivariate_normal([1.15,0], [[0.04, 0],[0,0.05]], 400).T\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Contour(\n",
    "        z=E_illustrate,\n",
    "        x=x_illustrate, \n",
    "        y=y_illustrate,\n",
    "        reversescale = True,\n",
    "        colorscale = \"viridis\",\n",
    "        contours=dict(\n",
    "            start=-10,\n",
    "            end=5,\n",
    "            size=1,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_a,\n",
    "        y=y_state_a,\n",
    "        mode=\"markers\",\n",
    "        name='',\n",
    "        marker_color=\"royalblue\"\n",
    "    ))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_b,\n",
    "        y=y_state_b,\n",
    "        mode=\"markers\",\n",
    "        name='',\n",
    "        marker_color=\"white\"\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title=\"Plot Title\",\n",
    "    width=600,\n",
    "    height=600,\n",
    "    xaxis_title=\"$x_1$\",\n",
    "    yaxis_title=\"$x_2$\",\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = -3,\n",
    "        dtick = 1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlaying their energies on an energy vs. $x$ plot (with the blue line representing the energy as a function of $x_1$ for $x_2$): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(x=x_illustrate, y=E(x_illustrate,0),name='Analytical'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_a,\n",
    "        y=E(x_state_a,y_state_a),\n",
    "        mode=\"markers\",\n",
    "        name='State A sample',\n",
    "        marker_color='yellowgreen'\n",
    "    ))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_state_b,\n",
    "        y=E(x_state_b,y_state_b),\n",
    "        mode=\"markers\",\n",
    "        name='State B sample',\n",
    "        marker_color=\"yellow\"\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"E\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to visualize the energies of these two states is by histogramming their values. First lets combine the input data into a single training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_state_a = np.stack((x_state_a,y_state_a),axis=1)\n",
    "coords_state_b = np.stack((x_state_b,y_state_b),axis=1)\n",
    "training_set = np.concatenate((coords_state_a,coords_state_b))\n",
    "print(training_set[0:5,:])\n",
    "np.random.shuffle(training_set) # shuffle rows of data\n",
    "print(training_set[0:5,:])\n",
    "training_set.shape # should be 1000 x 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(E(training_set[:,0],training_set[:,1]),bins=30)\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can clearly see the presence of the two distinct energy wells. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "The effect of changing the hyperparameters will be checked here. The hyperparameters defined are:\n",
    "\n",
    "-The ratio between the energy and entropy contribution in the kl loss.\n",
    "\n",
    "-The ratio Hamiltonian/entropy in the ml loss\n",
    "\n",
    "-Deepness of the network (layers in s and t networks as well as amount of masks)\n",
    "\n",
    "-\"Width\" of the network (amount of nodes per hidden layer, which are only incorporated in the s and t networks)\n",
    "\n",
    "-Sample size -- amount of samples used to perform the training by example as well as the amount of samples used to perform the training by energy.\n",
    "\n",
    "-iterations (number of steps in the training process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005]]\n",
    "ratios_kl_loss=[[1,1],[1,2],[1,3],[1,4],[1,5],[5,1],[4,1],[3,1],[2,1]]\n",
    "width_network=[256,512,1024]\n",
    "sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100]]\n",
    "# learning_rates=[[0.001,0.0005]]\n",
    "# ratios_kl_loss=[[1,1]]\n",
    "# width_network=[256]\n",
    "# sample_size=[[1000,1000]]\n",
    "# iterations=[[100,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ratios_kl_loss[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_variables(hid_lay=256, l_hid=3, iter_ex=100, iter_en=100, sample_size_ex=1000, sample_size_en=1000, lr_ex=0.001, lr_en=0.0005):\n",
    "    \n",
    "    nodes_per_hidden_layer=hid_lay\n",
    "    number_of_hidden_layers=l_hid\n",
    "    iterations_train_example=iter_ex\n",
    "    iterations_train_energy=iter_en\n",
    "    samples_for_training_example=sample_size_ex\n",
    "    samples_for_training_energy=sample_size_en\n",
    "    learning_rate_for_training_example=lr_ex\n",
    "    learning_rate_for_training_energy=lr_en\n",
    "\n",
    "    return nodes_per_hidden_layer, number_of_hidden_layers, iterations_train_example, iterations_train_energy, samples_for_training_example, samples_for_training_energy \\\n",
    "                ,learning_rate_for_training_example, learning_rate_for_training_energy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model (the triple well potential)\n",
    "triplewell = TripleWell()\n",
    "temperature = 1.0 # doesn't do anything\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                n_hidden, l_hidden, iter1, iter2, sample_size1, sample_size2, lr1, lr2 = define_variables(hid_lay=width, iter_ex=iter[0], iter_en=iter[1], sample_size_ex=size[0], sample_size_en=size[1], lr_ex=lr[0], lr_en=lr[1])\n",
    "\n",
    "                # Define the network architecture\n",
    "                nets = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2), nn.Tanh()) # net s\n",
    "                nett = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2)) # net t\n",
    "                masks = torch.from_numpy(np.array([[0, 1], [1, 0]] * 3).astype(np.float32)) # 6x2 matrix. len(masks) = 6 = num subblocks.\n",
    "                prior = distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))      # so we have a total of 3 neural blocks (see fig. 1 of boltzmann generators paper)\n",
    "                model = net.RealNVP(nets, nett, masks, prior, triplewell, (2,))\n",
    "\n",
    "                x_state_a, y_state_a = np.random.multivariate_normal([-1.15,0], [[0.04, 0],[0,0.05]], int(0.6*sample_size1)).T\n",
    "                x_state_b, y_state_b = np.random.multivariate_normal([1.15,0], [[0.04, 0],[0,0.05]], int(0.4*sample_size1)).T\n",
    "\n",
    "                coords_state_a = np.stack((x_state_a,y_state_a),axis=1)\n",
    "                coords_state_b = np.stack((x_state_b,y_state_b),axis=1)\n",
    "                training_set = np.concatenate((coords_state_a,coords_state_b))\n",
    "\n",
    "                optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr1) \n",
    "                training_set = training_set.astype('float32')\n",
    "                trainloader = data.DataLoader(dataset=training_set, batch_size=1000)\n",
    "\n",
    "                losses = [] # for visualizing loss as a function of iteration number rather than epoch number\n",
    "                t = 0 # iteration count\n",
    "\n",
    "                while t < iter1:\n",
    "                    for batch in trainloader:  \n",
    "\n",
    "                        # Custom ML loss function\n",
    "                        loss = model.loss_ml(batch) \n",
    "                        losses.append(loss.item()) # save values for plotting later \n",
    "\n",
    "                        # Training\n",
    "                        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "\n",
    "                        t = t + 1 # iteration count\n",
    "\n",
    "                # # Visualize loss\n",
    "                # fig = go.Figure() # plotly reference: https://plot.ly/python/line-charts/\n",
    "                # fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses,\n",
    "                #                     mode='lines',\n",
    "                #                     name='lines'))\n",
    "\n",
    "                # fig.update_layout(yaxis_title='Loss',\n",
    "                #                 xaxis_title='Iteration #')\n",
    "\n",
    "\n",
    "                z, x = model.sample(sample_size2)\n",
    "\n",
    "                optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr2) \n",
    "                training_set_2 = (z.astype('float32'))\n",
    "                trainloader_2 = data.DataLoader(dataset=training_set_2, batch_size=25000)\n",
    "\n",
    "                t = iter1\n",
    "\n",
    "                while t < iter1 + iter2:\n",
    "                    for batch_z in trainloader_2:  \n",
    "                        # KL loss function\n",
    "                        loss = model.loss_kl(batch_z)\n",
    "                        losses.append(loss.item()) # save values for plotting later \n",
    "\n",
    "                        # Training on KL loss\n",
    "                        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "\n",
    "                        t = t + 1 # iteration count\n",
    "\n",
    "                z1, x1 = model.sample(500000)\n",
    "\n",
    "                print(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\"+\"is trained\")\n",
    "\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",coords_state_a,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",coords_state_b,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",z,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",x,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",z1,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",x1,delimiter=\",\")\n",
    "\n",
    "                print(f\"and the data written to the files\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model (the triple well potential)\n",
    "triplewell = TripleWell()\n",
    "temperature = 1.0 # doesn't do anything\n",
    "\n",
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005]]\n",
    "ratios_kl_loss=[[1,1],[1,2],[1,3],[1,4],[1,5],[5,1],[4,1],[3,1],[2,1]]\n",
    "width_network=[256,512,1024]\n",
    "sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,25],[100,50],[100,75],[200,50]]\n",
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005]]\n",
    "ratios_kl_loss=[[1,1],[1,2],[1,3],[1,4],[1,5],[5,1],[4,1],[3,1],[2,1]]\n",
    "width_network=[256,512,1024]\n",
    "sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100]]\n",
    "# learning_rates=[[0.001,0.0005]]\n",
    "# ratios_kl_loss=[[1,1]]\n",
    "# width_network=[256]\n",
    "# sample_size=[[1000,1000]]\n",
    "# iterations=[[100,100]]\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                n_hidden, l_hidden, iter1, iter2, sample_size1, sample_size2, lr1, lr2 = define_variables(hid_lay=width, iter_ex=iter[0], iter_en=iter[1], sample_size_ex=size[0], sample_size_en=size[1], lr_ex=lr[0], lr_en=lr[1])\n",
    "\n",
    "                # Define the network architecture\n",
    "                nets = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2), nn.Tanh()) # net s\n",
    "                nett = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2)) # net t\n",
    "                masks = torch.from_numpy(np.array([[0, 1], [1, 0]] * 3).astype(np.float32)) # 6x2 matrix. len(masks) = 6 = num subblocks.\n",
    "                prior = distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))      # so we have a total of 3 neural blocks (see fig. 1 of boltzmann generators paper)\n",
    "                model = net.RealNVP(nets, nett, masks, prior, triplewell, (2,))\n",
    "\n",
    "                x_state_a, y_state_a = np.random.multivariate_normal([-1.15,0], [[0.04, 0],[0,0.05]], int(0.6*sample_size1)).T\n",
    "                x_state_b, y_state_b = np.random.multivariate_normal([1.15,0], [[0.04, 0],[0,0.05]], int(0.4*sample_size1)).T\n",
    "\n",
    "                coords_state_a = np.stack((x_state_a,y_state_a),axis=1)\n",
    "                coords_state_b = np.stack((x_state_b,y_state_b),axis=1)\n",
    "                training_set = np.concatenate((coords_state_a,coords_state_b))\n",
    "\n",
    "                optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr1) \n",
    "                training_set = training_set.astype('float32')\n",
    "                trainloader = data.DataLoader(dataset=training_set, batch_size=1000)\n",
    "\n",
    "                losses = [] # for visualizing loss as a function of iteration number rather than epoch number\n",
    "                t = 0 # iteration count\n",
    "\n",
    "                while t < iter1:\n",
    "                    for batch in trainloader:  \n",
    "\n",
    "                        # Custom ML loss function\n",
    "                        loss = model.loss_ml(batch) \n",
    "                        losses.append(loss.item()) # save values for plotting later \n",
    "\n",
    "                        # Training\n",
    "                        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "\n",
    "                        t = t + 1 # iteration count\n",
    "\n",
    "                # # Visualize loss\n",
    "                # fig = go.Figure() # plotly reference: https://plot.ly/python/line-charts/\n",
    "                # fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses,\n",
    "                #                     mode='lines',\n",
    "                #                     name='lines'))\n",
    "\n",
    "                # fig.update_layout(yaxis_title='Loss',\n",
    "                #                 xaxis_title='Iteration #')\n",
    "\n",
    "\n",
    "                z, x = model.sample(sample_size2)\n",
    "\n",
    "                optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr2) \n",
    "                training_set_2 = (z.astype('float32'))\n",
    "                trainloader_2 = data.DataLoader(dataset=training_set_2, batch_size=25000)\n",
    "\n",
    "                t = iter1\n",
    "\n",
    "                while t < iter1 + iter2:\n",
    "                    for batch_z in trainloader_2:  \n",
    "                        # KL loss function\n",
    "                        loss = model.loss_kl(batch_z)\n",
    "                        losses.append(loss.item()) # save values for plotting later \n",
    "\n",
    "                        # Training on KL loss\n",
    "                        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        optimizer.step()\n",
    "\n",
    "                        t = t + 1 # iteration count\n",
    "\n",
    "                z1, x1 = model.sample(500000)\n",
    "\n",
    "                print(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\"+\"is trained\")\n",
    "\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",coords_state_a,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",coords_state_b,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",z,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",x,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",z1,delimiter=\",\")\n",
    "                np.savetxt(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",x1,delimiter=\",\")\n",
    "\n",
    "                print(f\"and the data written to the files\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[100]\n",
    "sample_size=[[1000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[100]\n",
    "sample_size=[[1000,5000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[100]\n",
    "sample_size=[[5000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[128]\n",
    "sample_size=[[1000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[128]\n",
    "sample_size=[[1000,5000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[128]\n",
    "sample_size=[[5000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[256]\n",
    "sample_size=[[1000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[256]\n",
    "sample_size=[[1000,5000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[256]\n",
    "sample_size=[[5000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[512]\n",
    "sample_size=[[1000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[512]\n",
    "sample_size=[[1000,5000]]\n",
    "i=0\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cbook as cbook\n",
    "from matplotlib import cm\n",
    "import scipy.ndimage\n",
    "nbins=100\n",
    "from scipy.stats import kde\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[512]\n",
    "sample_size=[[5000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[1024]\n",
    "sample_size=[[1000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[1024]\n",
    "sample_size=[[1000,5000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[[0.001,0.00075],[0.001,0.0005],[0.001,0.00025],[0.001,0.0001],[0.01,0.0005],[0.0005,0.0005],[0.0001,0.0005],[0.001,0.001]]\n",
    "# width_network=[128,256,512,1024]\n",
    "# sample_size=[[1000,1000],[1000,5000],[5000,1000]]\n",
    "iterations=[[100,100],[100,25],[100,50],[100,75],[200,50],[100,125],[100,150],[100,175],[100,200],[100,300],[150,100],[200,100],[200,50]]\n",
    "width_network=[1024]\n",
    "sample_size=[[5000,1000]]\n",
    "i=0\n",
    "\n",
    "datadir=\"/Users/toon/Downloads/MLFC_project-BG-HFW_TVG-main/project/experiments/Data/Results_20_05_23/\"\n",
    "\n",
    "for width in width_network:\n",
    "    for size in sample_size:\n",
    "        for lr in learning_rates:\n",
    "            for iter in iterations:\n",
    "\n",
    "                file=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\"\n",
    "                \n",
    "                if (os.path.exists(datadir+file)):\n",
    "\n",
    "                    i+=1\n",
    "\n",
    "                    coords_state_a=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_a.csv\",delimiter=\",\")\n",
    "                    coords_state_b=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_coor_state_b.csv\",delimiter=\",\")\n",
    "                    z=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_before_training_energy.csv\",delimiter=\",\")\n",
    "                    x=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_before_training_energy.csv\",delimiter=\",\")\n",
    "                    z1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_z_after_training_energy.csv\",delimiter=\",\")\n",
    "                    x1=np.genfromtxt(datadir+f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}_x_after_training_energy.csv\",delimiter=\",\")\n",
    "\n",
    "                    globals()[f\"fig{i}\"], globals()[f\"axes{i}\"] = plt.subplots(2, 3, figsize = (10,6))\n",
    "\n",
    "                    fig=globals()[f\"fig{i}\"]\n",
    "                    axes=globals()[f\"axes{i}\"]\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(231)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(232)\n",
    "                    plt.scatter(z[:, 0], z[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(233)\n",
    "                    plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    # plot data sampled in real space \n",
    "                    plt.subplot(234)\n",
    "                    plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "                    plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "                    # sampling from the multivariate gaussian with zero mean and unit variance\n",
    "                    plt.subplot(235)\n",
    "                    plt.scatter(z1[:, 0], z1[:, 1])\n",
    "                    plt.xlim([-8,8])\n",
    "                    plt.ylim([-8,8])\n",
    "                    plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    k = kde.gaussian_kde(x1.T)\n",
    "                    xi, yi = np.mgrid[x1[:,0].min():x1[:,0].max():nbins*1j, x1[:,1].min():x1[:,1].max():nbins*1j]\n",
    "                    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "                    # sample 1000 points from prior and transform back \n",
    "                    plt.subplot(236)\n",
    "                    # plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "                    b=nbins*nbins\n",
    "                    plt.pcolormesh(xi, yi, zi.reshape(xi.shape)*b, norm=colors.LogNorm(vmin=1,vmax=(zi*b).reshape(xi.shape).max()), shading=\"gouraud\",cmap=plt.get_cmap('viridis'))\n",
    "                    plt.contour(xi, yi, zi.reshape(xi.shape) )\n",
    "\n",
    "                    plt.xlim([-4,4])\n",
    "                    plt.ylim([-4,4])\n",
    "                    plt.title(r'$X = g(z)$')\n",
    "\n",
    "                    st = fig.suptitle(f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}\", fontsize=\"x-large\")\n",
    "                    st.set_y(0.95)\n",
    "                    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "                    plt.savefig(fname=f\"lr={lr[0]}_{lr[1]}_width={width}_size={size[0]}_{size[1]}_iter={iter[0]}_{iter[1]}.png\", dpi=300, facecolor='white')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(datadir + file + \"does not exist\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y1 = [1, 4, 9, 16, 25]\n",
    "y2 = [1, 2, 4, 8, 16]\n",
    "y3 = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Create the first figure\n",
    "fig1 = plt.figure()\n",
    "plt.plot(x, y1)\n",
    "plt.title('Figure 1')\n",
    "\n",
    "# Create the second figure\n",
    "fig2 = plt.figure()\n",
    "plt.plot(x, y2)\n",
    "plt.title('Figure 2')\n",
    "\n",
    "# Create the third figure\n",
    "fig3 = plt.figure()\n",
    "plt.plot(x, y3)\n",
    "plt.title('Figure 3')\n",
    "\n",
    "# Display the figures\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 2, figsize = (12,10))\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(223)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "plt.subplot(222)\n",
    "plt.scatter(z1[:, 0], z1[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "plt.subplot(224)\n",
    "plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X = g(z)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boltzmann generator training\n",
    "We would now like to infer the energy landscape through direct sampling of a learned latent space description of this sytem. We achieve this by training a Boltzmann generator on the given input data. We begin by defining our network architecture, using the specifications given on pg. 4 of the SI of Noe et al.: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256  # number of nodes in each hidden layer\n",
    "temperature = 1.0 # doesn't do anything\n",
    "l_hidden = 3   # number of hidden layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There the training schedule is also specified. Let \"1\" in the following denote the first set of iterations (where only the ML loss is used) while \"2\" refers to the second second of iterations (where both the ML and KL loss is utilized): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter1 = 100\n",
    "iter2 = 200\n",
    "\n",
    "batch_size1 = 1000 # less than 1000 does not seem to converge \n",
    "batch_size2 = 50000\n",
    "\n",
    "lr1 = 0.001 # could not get monotonic decrease of loss with largest learning rates when using standard gradient descent. \n",
    "lr2 = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the Boltzmann generator network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Debugging\n",
    "n_hidden = 256\n",
    "\n",
    "# Define our model (the triple well potential)\n",
    "triplewell = TripleWell()\n",
    "\n",
    "# Define the network architecture\n",
    "nets = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2), nn.Tanh()) # net s\n",
    "nett = lambda: nn.Sequential(nn.Linear(2, n_hidden), nn.ReLU(), nn.Linear(n_hidden, n_hidden), nn.ReLU(), nn.Linear(n_hidden, 2)) # net t\n",
    "masks = torch.from_numpy(np.array([[0, 1], [1, 0]] * 3).astype(np.float32)) # 6x2 matrix. len(masks) = 6 = num subblocks.\n",
    "prior = distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))      # so we have a total of 3 neural blocks (see fig. 1 of boltzmann generators paper)\n",
    "model = net.RealNVP(nets, nett, masks, prior, triplewell, (2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training by example\n",
    "Time to train the model. We first \"train by example\" by computing only the ML loss. This loss essentially maximizes the likelihood of our input configurations in the latent space Gaussian distribution. \n",
    "\n",
    "In contrast, the KL loss promotes sampling of low-energy states; it also includes an entropic contribution to penalize repeated sampling of the same stable state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr1) \n",
    "training_set = training_set.astype('float32')\n",
    "trainloader = data.DataLoader(dataset=training_set, batch_size=batch_size1)\n",
    "\n",
    "losses = [] # for visualizing loss as a function of iteration number rather than epoch number\n",
    "t = 0 # iteration count\n",
    "\n",
    "while t < iter1:\n",
    "    for batch in trainloader:  \n",
    "\n",
    "        # Custom ML loss function\n",
    "        loss = model.loss_ml(batch) \n",
    "        losses.append(loss.item()) # save values for plotting later \n",
    "    \n",
    "        # Training\n",
    "        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        t = t + 1 # iteration count\n",
    "        if t % 25 == 0:\n",
    "            print('iter %s:' % t, 'loss = %.3f' % loss)\n",
    "\n",
    "# Visualize loss\n",
    "fig = go.Figure() # plotly reference: https://plot.ly/python/line-charts/\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses,\n",
    "                    mode='lines',\n",
    "                    name='lines'))\n",
    "\n",
    "fig.update_layout(yaxis_title='Loss',\n",
    "                   xaxis_title='Iteration #')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from the above plot of the ML loss that the model has been succesfully trained. Let's confirm this by now sampling from the learned latent space distribution and trying to then infer the energy landscape in real space from these samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 2, figsize = (12,10))\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(223)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "# sample from x and transform to z \n",
    "z_md_a = model.f(torch.from_numpy(coords_state_a.astype('float32')))[0].detach().numpy()\n",
    "z_md_b = model.f(torch.from_numpy(coords_state_b.astype('float32')))[0].detach().numpy()\n",
    "plt.subplot(221)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue')\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue')\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.title(r'$z = f(X)$')\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "z, x = model.sample(2000)\n",
    "plt.subplot(222)\n",
    "plt.scatter(z[:, 0], z[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "plt.subplot(224)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X = g(z)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model.energies,bins=40)\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training by energy\n",
    "We will now train with the KL loss to teach the network to focus on both low energy states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad==True], lr=lr2) \n",
    "training_set_2 = (z.astype('float32'))\n",
    "trainloader_2 = data.DataLoader(dataset=training_set_2, batch_size=batch_size2)\n",
    "\n",
    "t = iter1\n",
    "\n",
    "while t < iter1 + iter2:\n",
    "    for batch_z in trainloader_2:  \n",
    "        # KL loss function\n",
    "        loss = model.loss_kl(batch_z)\n",
    "        losses.append(loss.item()) # save values for plotting later \n",
    "    \n",
    "        # Training on KL loss\n",
    "        optimizer.zero_grad() # Set grads to zero, else PyTorch will accumulate gradients on each backprop\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        t = t + 1 # iteration count\n",
    "\n",
    "        if \n",
    "\n",
    "        if t % 25 == 0:\n",
    "            print('iter %s:' % t, 'loss = %.3f' % loss)\n",
    "\n",
    "# Visualize loss\n",
    "fig = go.Figure() # plotly reference: https://plot.ly/python/line-charts/\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses,\n",
    "                    mode='lines',\n",
    "                    name='lines'))\n",
    "\n",
    "fig.update_layout(yaxis_title='Loss', xaxis_title='Iteration #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 2, figsize = (12,10))\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(223)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X \\sim p(X)$')\n",
    "\n",
    "# sample from x and transform to z \n",
    "z_md_a = model.f(torch.from_numpy(coords_state_a.astype('float32')))[0].detach().numpy()\n",
    "z_md_b = model.f(torch.from_numpy(coords_state_b.astype('float32')))[0].detach().numpy()\n",
    "plt.subplot(221)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue')\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue')\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.title(r'$z = f(X)$')\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "z1, x1 = model.sample(500000)\n",
    "plt.subplot(222)\n",
    "plt.scatter(z1[:, 0], z1[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.title(r'$z \\sim p(z)$')\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "plt.subplot(224)\n",
    "plt.scatter(x1[:, 0], x1[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.title(r'$X = g(z)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 2, figsize = (8,8))\n",
    "my_font_size = 16 # for paper\n",
    "my_s = 2\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(223)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X \\sim p(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sample from x and transform to z \n",
    "z_md_a = model.f(torch.from_numpy(coords_state_a.astype('float32')))[0].detach().numpy()\n",
    "z_md_b = model.f(torch.from_numpy(coords_state_b.astype('float32')))[0].detach().numpy()\n",
    "plt.subplot(221)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue')\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue')\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z = f(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "plt.subplot(222)\n",
    "plt.scatter(z[:, 0], z[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z \\sim p(z)$', fontsize = my_font_size)\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "x = model.g(torch.from_numpy(z))[0].detach().numpy()\n",
    "plt.subplot(224)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X = g(z)$', fontsize = my_font_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"images/double_well_results2x2.png\", dpi=600, transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (6,4))\n",
    "\n",
    "plt.contour(x_illustrate, y_illustrate, E_illustrate,np.arange(-10, 5, 1),extend='both',colors='k');\n",
    "clb = plt.colorbar()\n",
    "clb.ax.set_title(r'$H(\\mathbf{x})$')\n",
    "\n",
    "my_font_size = 16 \n",
    "plt.xlabel(r\"$x_1$\", fontsize = my_font_size)\n",
    "plt.ylabel(r\"$x_2$\", fontsize = my_font_size)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r', alpha=0.1) \n",
    "plt.xlim([-2.5,2.5])\n",
    "plt.ylim([-2,3])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/double_well_potential.png\", dpi=600, transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of the report, we will visualize the data in a different order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 2, figsize = (8,8))\n",
    "my_font_size = 16 # for paper\n",
    "my_s = 2\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(223)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X \\sim p(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sample from x and transform to z \n",
    "z_md_a = model.f(torch.from_numpy(coords_state_a.astype('float32')))[0].detach().numpy()\n",
    "z_md_b = model.f(torch.from_numpy(coords_state_b.astype('float32')))[0].detach().numpy()\n",
    "plt.subplot(221)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue')\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue')\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z = f(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "z, x = model.sample(100000)\n",
    "plt.subplot(222)\n",
    "plt.scatter(z[:, 0], z[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z \\sim p(z)$', fontsize = my_font_size)\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "x = model.g(torch.from_numpy(z))[0].detach().numpy()\n",
    "plt.subplot(224)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X = g(z)$', fontsize = my_font_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"images/double_well_results2x2.png\", dpi=600, transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(1,4, figsize = (12,3)) # width x height in inches\n",
    "my_font_size = 16 # for paper\n",
    "my_s = 2\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(141)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r',s = my_s)\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon',s = my_s)\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X \\sim p(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sample from x and transform to z \n",
    "plt.subplot(142)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue',s = my_s)\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue',s = my_s)\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z = f(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "plt.subplot(143)\n",
    "plt.scatter(z[:, 0], z[:, 1],s = my_s)\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z \\sim p(z)$', fontsize = my_font_size)\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "plt.subplot(144)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r',s = my_s) # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X = g(z)$', fontsize = my_font_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"images/double_well_results.png\", dpi=600, transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned transformation (After training)\n",
    "fig, axes = plt.subplots(2, 1, figsize = (8,4))\n",
    "my_font_size = 16 # for paper\n",
    "my_s = 2\n",
    "\n",
    "# plot data sampled in real space \n",
    "plt.subplot(121)\n",
    "plt.scatter(coords_state_a[:, 0], coords_state_a[:, 1], c='r')\n",
    "plt.scatter(coords_state_b[:, 0], coords_state_b[:, 1], c='salmon')\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X \\sim p(X)$', fontsize = my_font_size)\n",
    "\n",
    "# sample from x and transform to z \n",
    "z_md_a = model.f(torch.from_numpy(coords_state_a.astype('float32')))[0].detach().numpy()\n",
    "z_md_b = model.f(torch.from_numpy(coords_state_b.astype('float32')))[0].detach().numpy()\n",
    "plt.subplot(122)\n",
    "plt.scatter(z_md_a[:, 0], z_md_a[:, 1], c='tab:blue')\n",
    "plt.scatter(z_md_b[:, 0], z_md_b[:, 1], c='lightskyblue')\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z = f(X)$', fontsize = my_font_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"images/double_well_results_2x1_top.png\", dpi=600, transparent=False)\n",
    "fig, axes = plt.subplots(2, 1, figsize = (8,4))\n",
    "\n",
    "# sampling from the multivariate gaussian with zero mean and unit variance\n",
    "plt.subplot(121)\n",
    "plt.scatter(z[:, 0], z[:, 1])\n",
    "plt.xlim([-8,8])\n",
    "plt.ylim([-8,8])\n",
    "plt.xlabel(r\"$z_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$z_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$z \\sim p(z)$', fontsize = my_font_size)\n",
    "\n",
    "# sample 1000 points from prior and transform back \n",
    "x = model.g(torch.from_numpy(z))[0].detach().numpy()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x[:, 0], x[:, 1], c='r') # x[:, 0, 0] is x1 coordinates of all samples \n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.xlabel(r\"$x_1$\",fontsize = 0.9*my_font_size)\n",
    "plt.ylabel(r\"$x_2$\",fontsize = 0.9*my_font_size)\n",
    "plt.title(r'$X = g(z)$', fontsize = my_font_size)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"images/double_well_results_2x1_bottom.png\", dpi=600, transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Energy\n",
    "With our model now correctly generating the Boltzmann distribution (bottom right), we can utilize it to calculate the free energy as a function of the reaction coordinate for this system (the coordinate $x_1$). The Boltzmann distribution is given by: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(x) = \\exp(-f(x))$ so $f = -\\log(p(x))$ where $f$ denote free energy. \n",
    "\n",
    "Steps:\n",
    "\n",
    "1) Histogram the obtained samples to estimate probs\n",
    "\n",
    "2) Filter probabilities to avoid single-sample, low-prob. states that are likely just noise\n",
    "\n",
    "3) Calculate free energy\n",
    "\n",
    "4) Shift free energy to lowest well reference state (we only get relative $f - f_0$)\n",
    "\n",
    "\n",
    "Note: The smoothness of the average can be improved by generating more sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_fe, x_fe = model.sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_fe[:,0]\n",
    "x2 = x_fe[:,1]\n",
    "\n",
    "counts, bins = np.histogram(x1, bins = 200)\n",
    "anchors = (bins[1:] + bins[:-1]) / 2\n",
    "\n",
    "probs = counts / np.sum(counts)\n",
    "\n",
    "anchors = anchors[np.where(probs > 0.0001)]\n",
    "probs = probs[np.where(probs > 0.0001)]\n",
    "\n",
    "f = -np.log(probs)\n",
    "fn = f - np.min(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.scatter(anchors, fn) \n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(r\"$(f - f_0) / k_B T$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simple double well potential, we can also calculate this free energy analytically. The partition function $Z$ is given by: \n",
    "$$ \\ln Z(x_1) = \\sqrt{2\\pi}\\big( x_1^4 - 6*x_1^2 + x_1 \\big)$$\n",
    "from which we can calculate the free energy via $f=-k_B T \\ln Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (6,4))\n",
    "x1 = np.linspace(-2.5,2.5,1000)\n",
    "logz = (x1**4 - 6*x1**2 + x1) + 11\n",
    "\n",
    "plt.plot(x1,logz)\n",
    "plt.scatter(anchors, fn,color='orange') \n",
    "\n",
    "plt.xlabel(\"$x_1$\", fontsize = my_font_size)\n",
    "plt.ylabel(r\"$(f - f_0) / k_B T$\", fontsize = my_font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/double_well_fe.png\", dpi=600, transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- List of Plotly colors: https://community.plot.ly/t/plotly-colours-list/11730/3"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
